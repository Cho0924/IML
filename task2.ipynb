{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2e81b29c71eb2b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Task 2\n",
    "This serves as a template which will guide you through the implementation of this task. It is advised to first read the whole template and get a sense of the overall structure of the code before trying to fill in any of the TODO gaps.\n",
    "This is the jupyter notebook version of the template. For the python file version, please refer to the file `template_solution.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de347e31d213bd5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "First, we import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e071b8e282a8d6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T18:47:37.485752Z",
     "start_time": "2024-03-10T18:47:37.479263Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Add any other imports you need here\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from functools import reduce\n",
    "from sklearn import linear_model\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f2086e18dd7b5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Data Loading\n",
    "TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "(and potentially change initialization of variables to accomodate how you deal with non-numeric data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402e111cb0d70236",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "Shape: (900, 11)\n",
      "   season  price_AUS  price_CHF  price_CZE  price_GER  price_ESP  price_FRA  \\\n",
      "0  spring        NaN   9.644028  -1.686248  -1.748076  -3.666005        NaN   \n",
      "1  summer        NaN   7.246061  -2.132377  -2.054363  -3.295697  -4.104759   \n",
      "\n",
      "   price_UK  price_ITA  price_POL  price_SVK  \n",
      "0 -1.822720  -3.931031        NaN  -3.238197  \n",
      "1 -1.826021        NaN        NaN  -3.212894  \n",
      "\n",
      "\n",
      "Test data:\n",
      "(100, 10)\n",
      "   season  price_AUS  price_CZE  price_GER  price_ESP  price_FRA  price_UK  \\\n",
      "0  spring        NaN   0.472985   0.707957        NaN  -1.136441 -0.596703   \n",
      "1  summer  -1.184837   0.358019        NaN  -3.199028  -1.069695       NaN   \n",
      "\n",
      "   price_ITA  price_POL  price_SVK  \n",
      "0        NaN   3.298693   1.921886  \n",
      "1  -1.420091   3.238307        NaN  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This loads the training and test data, preprocesses it, removes the NaN\n",
    "values and interpolates the missing data using imputation\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Compute\n",
    "----------\n",
    "X_train: matrix of floats, training input with features\n",
    "y_train: array of floats, training output with labels\n",
    "X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "\"\"\"\n",
    "# Load training data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "    \n",
    "print(\"Training data:\")\n",
    "print(\"Shape:\", train_df.shape)\n",
    "print(train_df.head(2))\n",
    "print('\\n')\n",
    "    \n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(\"Test data:\")\n",
    "print(test_df.shape)\n",
    "print(test_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d10e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy initialization of the X_train, X_test and y_train   \n",
    "# TODO: Depending on how you deal with the non-numeric data, you may want to \n",
    "# modify/ignore the initialization of these variables   \n",
    "\n",
    "#drop rows with no chf values\n",
    "train_df.dropna(subset=[\"price_CHF\"], inplace=True)\n",
    "\n",
    "X_train = np.zeros_like(train_df.drop(['price_CHF'],axis=1))\n",
    "y_train = np.zeros_like(train_df['price_CHF'])\n",
    "X_test = np.zeros_like(test_df)\n",
    "\n",
    "# TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "def preprocess(df):\n",
    "\n",
    "\n",
    "  #add new columns \"is_##\" and make the column values binary\n",
    "  df[\"is_spring\"] = (df[\"season\"]==\"spring\").map(lambda x : 1 if x else 0)\n",
    "  df[\"is_summer\"] = (df[\"season\"]==\"summer\").map(lambda x : 1 if x else 0)\n",
    "  df[\"is_autumn\"] = (df[\"season\"]==\"autumn\").map(lambda x : 1 if x else 0)\n",
    "  df[\"is_winter\"] = (df[\"season\"]==\"winter\").map(lambda x : 1 if x else 0)\n",
    "  dropped_season = df.drop(\"season\", axis=1)\n",
    "\n",
    "  imp = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "  SEASONS = [\"spring\", \"summer\", \"autumn\", \"winter\"]\n",
    "  imputed_df = reduce(lambda df1, df2 : pd.concat([df1, df2]) , [pd.DataFrame(imp.fit_transform(dropped_season[dropped_season[f\"is_{s}\"] == 1]), columns=dropped_season.columns, index=dropped_season[dropped_season[f\"is_{s}\"] == 1].index) for s in SEASONS]).sort_index()\n",
    "  return imputed_df\n",
    "\n",
    "\n",
    "imputed_train = preprocess(train_df)\n",
    "y_train = imputed_train[\"price_CHF\"]\n",
    "X_train = imputed_train.drop(\"price_CHF\", axis=1)\n",
    "X_test = preprocess(test_df)\n",
    "\n",
    "assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (X_test.shape[0] == 100), \"Invalid data shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8845f012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     price_AUS  price_CZE  price_GER  price_ESP  price_FRA  price_UK  \\\n",
      "0    -2.127053  -1.686248  -1.748076  -3.666005  -4.030793 -1.822720   \n",
      "1    -2.087594  -2.132377  -2.054363  -3.295697  -4.104759 -1.826021   \n",
      "2    -2.101937  -1.910282  -1.955927  -3.388777  -4.120762 -2.034409   \n",
      "3    -2.098475  -1.903834  -2.002881  -3.588235  -4.041085 -2.214720   \n",
      "4    -1.969687  -1.697257  -1.331049  -3.604443  -3.911096 -2.388092   \n",
      "..         ...        ...        ...        ...        ...       ...   \n",
      "889  -0.650417   0.235917  -0.306331  -3.426546  -2.735177 -1.839910   \n",
      "890  -1.079859   0.420600  -0.226806  -3.408693  -2.597671 -1.807515   \n",
      "891  -0.961371   0.352449  -0.361710  -3.488688  -2.535157 -1.568924   \n",
      "894  -1.186919   0.554047   0.236214  -3.333672  -2.262145 -1.246151   \n",
      "896  -1.061639   0.281646   0.695157  -3.466753  -1.929701 -1.005468   \n",
      "\n",
      "     price_ITA  price_POL  price_SVK  is_spring  is_summer  is_autumn  \\\n",
      "0    -3.931031  -2.308758  -3.238197        1.0        0.0        0.0   \n",
      "1    -3.755658  -2.683186  -3.212894        0.0        1.0        0.0   \n",
      "2    -4.073850  -2.771291  -3.114061        0.0        0.0        1.0   \n",
      "3    -4.018620  -2.330803  -3.374320        0.0        0.0        0.0   \n",
      "4    -4.093946  -2.364571  -3.110845        1.0        0.0        0.0   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "889  -2.378179   2.535228   2.125453        0.0        1.0        0.0   \n",
      "890  -2.223057   2.555153   2.189913        0.0        0.0        1.0   \n",
      "891  -2.396703   2.706716   2.520366        0.0        0.0        0.0   \n",
      "894  -1.801203   1.759145   1.715936        0.0        0.0        1.0   \n",
      "896  -1.508756   3.187263   1.647064        1.0        0.0        0.0   \n",
      "\n",
      "     is_winter  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          1.0  \n",
      "4          0.0  \n",
      "..         ...  \n",
      "889        0.0  \n",
      "890        0.0  \n",
      "891        1.0  \n",
      "894        0.0  \n",
      "896        0.0  \n",
      "\n",
      "[631 rows x 13 columns]\n",
      "0      9.644028\n",
      "1      7.246061\n",
      "2      7.620085\n",
      "3      8.411894\n",
      "4      8.926884\n",
      "         ...   \n",
      "889    3.237347\n",
      "890    2.679221\n",
      "891    3.633928\n",
      "894   -0.303802\n",
      "896   -1.734754\n",
      "Name: price_CHF, Length: 631, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae934cf",
   "metadata": {},
   "source": [
    "# Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c4312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6756bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to try new kernels, add that kernel to this list\n",
    "kernel_list = [DotProduct() + WhiteKernel(),\n",
    "               RBF() + WhiteKernel(),\n",
    "               RBF(length_scale=1.5) + WhiteKernel(),\n",
    "               Matern() + WhiteKernel(),\n",
    "               RationalQuadratic() + WhiteKernel()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959037466887e870",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Modeling and Prediction\n",
    "TODO: Define the model and fit it using training data. Then, use test data to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fb0d86b605f9813",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 0th kernel: DotProduct(sigma_0=1) + WhiteKernel(noise_level=1)\n",
      "mean scores=0.7521618763783592\n",
      "training with 1th kernel: RBF(length_scale=1) + WhiteKernel(noise_level=1)\n",
      "mean scores=0.9467600870891089\n",
      "training with 2th kernel: RBF(length_scale=1.5) + WhiteKernel(noise_level=1)\n",
      "mean scores=0.9467600917196849\n",
      "training with 3th kernel: Matern(length_scale=1, nu=1.5) + WhiteKernel(noise_level=1)\n",
      "mean scores=0.9467050410778904\n",
      "training with 4th kernel: RationalQuadratic(alpha=1, length_scale=1) + WhiteKernel(noise_level=1)\n",
      "mean scores=0.9440817064455663\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This defines the model, fits training data and then does the prediction\n",
    "with the test data \n",
    "\n",
    "Parameters\n",
    "----------\n",
    "X_train: matrix of floats, training input with 10 features\n",
    "y_train: array of floats, training output\n",
    "X_test: matrix of floats: dim = (100, ?), test input with 10 features\n",
    "\n",
    "Compute\n",
    "----------\n",
    "y_test: array of floats: dim = (100,), predictions on test set\n",
    "\"\"\"\n",
    "\n",
    "#TODO: Define the model and fit it using training data. Then, use test data to make predictions\n",
    "y_pred=np.zeros(X_test.shape[0])\n",
    "n_folds = 10\n",
    "kf = KFold(n_splits=n_folds)\n",
    "score_mat = np.zeros((len(kernel_list), n_folds))\n",
    "\n",
    "X_np_train = X_train.to_numpy()\n",
    "y_np_train = y_train.to_numpy()\n",
    "\n",
    "for k in range(len(kernel_list)):\n",
    "    print(f\"training with {k}th kernel: {kernel_list[k]}\")\n",
    "    kernel = kernel_list[k]\n",
    "    \n",
    "    f = 0\n",
    "    for train, test in kf.split(X_np_train):\n",
    "        gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)\n",
    "        gpr.fit(X_np_train[train], y_np_train[train])\n",
    "        score_mat[k][f] = gpr.score(X_np_train[test], y_np_train[test])\n",
    "        f += 1\n",
    "\n",
    "   \n",
    "    print(f\"mean scores={np.mean(score_mat[k])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58931ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75216188 0.94676009 0.94676009 0.94670504 0.94408171]\n"
     ]
    }
   ],
   "source": [
    "#error score of the validation set prediction result from each kernel method\n",
    "#Bigger score is better. At most can become 1 == no error \n",
    "avg_scores = np.mean(score_mat, axis=1)\n",
    "print(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ab2118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF(length_scale=1.5) + WhiteKernel(noise_level=1)\n"
     ]
    }
   ],
   "source": [
    "#choose the optimal kernel\n",
    "opt_kernel = kernel_list[np.argmax(avg_scores, axis=0)]\n",
    "print(opt_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e747efe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9919654425380167\n"
     ]
    }
   ],
   "source": [
    "#train with the whole training data set\n",
    "gpr_opt = GaussianProcessRegressor(kernel=opt_kernel, n_restarts_optimizer=5)\n",
    "gpr_opt.fit(X_train, y_train)\n",
    "print(gpr_opt.score(X_train, y_train))\n",
    "#predict\n",
    "y_pred = gpr_opt.predict(X_test)\n",
    "assert y_pred.shape == (100,), \"Invalid data shape\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c62e0cd4cec5a7e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Saving Results\n",
    "You don't have to change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "382d87d2d67ddbdc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results file successfully generated!\n"
     ]
    }
   ],
   "source": [
    "dt = pd.DataFrame(y_pred) \n",
    "dt.columns = ['price_CHF']\n",
    "dt.to_csv('results.csv', index=False)\n",
    "print(\"\\nResults file successfully generated!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
